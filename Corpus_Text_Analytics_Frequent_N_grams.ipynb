{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Read a File with open(file, mode) and then file.read() or file.readlines()\n",
    "### - LowerCase\n",
    "### - Convert to a List of Tokens\n",
    "### - Remove Stopwords - list FILTER() function\n",
    "### - Remove Punctuation / junk characters\n",
    "### - Show Distinct Words (SET Operator)\n",
    "### - Get Most Occuring Words \n",
    "### - Get most common N-Grams using NLTK\n",
    "### - Get Keyword Density..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = '1. The name India is derived from the river Indus. It is a valley around which people settled in earlier times ' \\\n",
    "'2. India is the world’s oldest, largest and continuous civilization – the Indus Valley civilization. ' \\\n",
    "'3. India is also one of the largest democracies in the world. ' \\\n",
    "'4. India has the largest postal system in the world with more than 150,000 post offices, which is thrice the size of that of China.' \\\n",
    "'5. India has more than 300,000 active mosques. This outnumbers any other country in the world, even the Muslim countries. ' \\\n",
    "'6. The second largest pool of engineers and scientists is from India.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. The name India is derived from the river Indus. It is a valley around which people settled in earlier times 2. India is the world’s oldest, largest and continuous civilization – the Indus Valley civilization. 3. India is also one of the largest democracies in the world. 4. India has the largest postal system in the world with more than 150,000 post offices, which is thrice the size of that of China.5. India has more than 300,000 active mosques. This outnumbers any other country in the world, even the Muslim countries. 6. The second largest pool of engineers and scientists is from India.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = open(file='skills.txt',mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_io.TextIOWrapper"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = doc3.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be researching, developing and implementing deep learning frameworks (Keras, TensorFlow, PyTorch, MxNet etc) \n",
      "Python OR C++ AND (Caffe, Tensorflow, PyTorch etc)\n",
      "Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Dockers, MySQL, etc.\n",
      "Experience visualizing/presenting data for stakeholders using: Tableau, High charts, D3, gg plot, etc.\n",
      "Highly proficient in languages and tools used in ML modeling like R, Python (SciKit Learn, SciPy, Numpy, etc.), \n",
      "Apache Spark (Scala or Python), H2O, Weka, TensorFlow, Torch, Keras.\n",
      "Highly proficient in languages and tools used in ML modeling like R, Python (SciKit Learn, SciPy, Numpy, etc.), \n",
      "Apache Spark (Scala or Python), H2O, Weka, TensorFlow, Torch, Keras.\n",
      "Preferred hands-on experience in coding in C, C++, Java, Scala or any other.\n",
      "Preferred experience in Big Data tools like Hadoop, Pig, Hive, MapReduce or any other.\n",
      "Prior experience with Big Data platforms/tools (Hadoop, MongoDB, Cassandra, etc.) \n",
      "Working proficiency in at least one data mining tool (SAS, SPSS, R, RapidMiner, etc.)\n",
      "Prior experience with Big\n",
      "3+ years design/implementation/consulting experience training Machine Learning models and deploying scoring pipelines at scale.\n",
      "3+ years professional experience in software development in languages like Java, Python, Scala. \n",
      "Have worked and deployed on technologies such as AWS, Azure, Google Cloud, Hadoop, RDBMS, MongoDB, NoSQL and/or Hive\n",
      "Have experience with ETL, NLP, AI, ML and/or DP will be advantageous\n",
      "Experience with MapReduce/Hadoop and related technologies (e.g., Pig, Hive, Cascading).\n",
      "Familiarity with Amazon Web Services and Elastic MapReduce a plus.\n",
      "Familiarity with Hadoop based commercial packages (e.g. Cloudera, Hortonworks\n",
      "Experience in text mining/NLP\n",
      "Experience with Python or C++ programming language.\n",
      "Experience working with RESTful API and general service oriented architectures.\n",
      "Experience managing teams of Data Scientists, Machine Learning Engineers, Software Engineers and/or Consultants \n",
      "An exceptional Data Modelling background with experience across one or more of the following tools R, Python, SPSS, Matlab\n",
      "Build products alongside the Core engineering team and evolve the engineering process to scale with data, handling complex problems and advanced client situations\n",
      "Be able to focus on modelling by working alongside the Data Engineering team which focuses on the wrangling, clean-up and transformation of data.\n",
      "Deep understanding on feature selection and modelling. Familiar with the theories behind common models (logistic regression, random forest, boosting trees, neural network etc.), and experienced in fine-tuning.\n",
      "Familiar with Apache Spark.\n",
      "Experience using Robotics Frameworks, RPA software products like Blue Prism, UiPath, Automation Anywhere, Kofax, etc\n",
      "Professional knowledge of Machine Learning environments, such as Regression or Decision Trees or Random Forest or Deep Learning\n",
      "Experience designing and deploying with one or more the technologies like Tensor Flow, Spark ML, CNTK, Torch, Caffe\n",
      "Knowledge of Big Data technologies, such as Spark, Hadoop, Cornerstone is highly desirable\n",
      "Good knowledge of databases like SQL, PostgreSQL, Mongo, Redis, Cassandra\n",
      "Exposure to Node & Scala, is desirable.Proficient in Python and related data processing libraries such as pandas and numpy.\n",
      "Solid coding skills in Python, R, Java, MySQL/NoSQL\n",
      "Familiar with deep learning topologies\n",
      "Experience with cloud platforms such as GCP\n",
      "Data pipeline skills: Spark, Celery, Jinja\n",
      "Professional experience with cloud native architectures and design, specifically AWS services such as S3, Lambda, EC2, RDS (Postgres), API Gateway, ECR and Fargate\n",
      "Experience building continuous integration pipelines for containerized machine learning models\n",
      "Experience in geospatial/geolocation analysis and neural networks\n",
      "Comfortable with devops and infrastructure technologies such as Terraform, CircleCI, Docker and the Serverless Framework\n",
      "Develop scalable tools leveraging machine learning and deep learning models to solve real-world problems in areas such as Speech Recognition, Natural Language Processing and Time Series predictions.\n",
      "Collaborate with all of JPMorgan Chase's lines of businesses, such as Investment Bank, Commercial Bank, and Asset Management.Lead your own project. \n",
      "Suggest, collect and synthesize requirements. \n",
      "Create an effective roadmap towards the deployment of a production-level machine learning application.\n",
      "MS or PhD in a quantitative discipline, e.g. Computer Science, Mathematics, Operations Research, Data Science, or similar BS with 2+ years of experience in a highly quantitative position.\n",
      "Experience in Deep Learning: DNN, CNN, RNN/LSTM, GAN or other auto encoder (AE).\n",
      "2+ years of hands-on experience developing machine learning models.\n",
      "Ability to develop and debug in Python, Java, C or C++. \n",
      "Proficient in git version control. R and Matlab are also relevant.\n",
      "Extensive experience with machine learning APIs and computational packages (TensorFlow, Theano, PyTorch, Keras, Scikit-Learn, NumPy, SciPy, Pandas, statsmodels).\n",
      "Familiarity with generation of heatmaps and biplots a plus\n",
      "Best practices in software development and productionise machine learning by working with our Machine Learning Engineering teams which optimise code for model development and scale it\n",
      "Work with our UX and Visual Design teams to interpret your complex models into stunning and user-focused visualisations\n",
      "A strong understanding of Data Engineering and Ingestion with experience across a range of Datastores that could include Hadoop, Spark, Teradata, AWS Redshift, MPP, Greenplum, Oracle, MongoDB, SQL, Cassandra\n",
      "Strong Data Visualisation skills across Qlikview and/or Tableau\n",
      "Masters or PHD in an analytical or technical field - Mathematics, Statistics, Computer Science, Physics or Engineering\n",
      "Minimum 3 years working experience manipulating data sets and building statistical models, has a Master’s in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with the software/tools\n",
      "Experience with Machine and Deep Learning toolkits such as MXNet, TensorFlow, Caffe and Torch.\n",
      "Experience with Big Data platforms like Apache Spark and Hadoop.\n",
      "Experienced in data processing with Python, R & SQL.\n",
      "Experience with AWS services related to AI/ML highly desirable, particularly Amazon EMR, AWS Lambda, SageMaker, Machine Learning, IoT, Amazon DynamoDB, Amazon S3, Amazon EC2 Container Service, Green Grass etc.\n",
      "Experience with SAS, SPSS, Python, R, Hadoop or SQL an advantage\n",
      "Experience with databases in general (more so the newer NoSQL DBs) and visualization tools (such as QlikView, Tableau etc ).\n",
      "Preferred experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms (including tools such as R)\n",
      "Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping.\n",
      "Java and/or Scala programming is a plus\n",
      "Extracting and transforming data from systems like Hadoop and SQL, using tools such as Pig, Scalding, Hive, Presto\n",
      "Some experience with one or more object oriented languages like Java, Scala, C++\n",
      "Some experience with scripting languages like Python or Ruby etc.\n",
      "Some experience with statistical programming environments like R or Matlab\n",
      "Experience with large datasets and Map Reduce architectures like Hadoop and open source data mining and machine learning projects\n",
      "Experience using SQL analyzing datasets with databases such as Presto, Teradata, Oracle, and MySQL\n",
      "Experience using R, Python, Stata, or other scripting languages for data prep, analysis, and machine learning\n",
      "Experience with applied social science research or familiarity with publicly-available government data sets such as those provided by Eurostat, the Office for National Statistics (UK), INSEE (France) the World Bank, the UN, the BLS and Census Bureau (US) and other national and international statistical agencies\n",
      "Familiarity with data visualization and/or BI tools (Ex. Tableau, PowerBI)\n",
      "Experience with Hadoop (Hive, Pig, or MapReduce)\n",
      "Deep knowledge of some of the popular ML frameworks such as SparkML, Tensorflow, scikit-learn, XGBoost, H2o etc. \n",
      "Ability to translate business problems into analytical structures and can be solved using statistical/ML techniques\n",
      "Expert proficiency in a structured programming language is a must – experience in at least one statistical/general purpose scripting languages like R or Python is mandatory\n",
      "At least 4 years of relevant experience, which should include hands-on programming in one(or more) of the languages specified above\n",
      "Understanding of concepts to analyze text, image, video etc. is a plus (not mandatory)\n",
      "Experience with technologies such as Spark ML, TensorFlow, Open CV, Caffe etc. is a plus(not mandatory)\n",
      "Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms\n",
      "Fluency in a programming language (Python, R, Java, SQL,Hadoop,ML,DL,NLP)\n",
      "Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop,Pig,Hive, Spark, Tableau)\n",
      "Experience in building large scale distributed ML Models Experience in building modern Machine Learning platforms a big plus.\n",
      "Experience with Human Computer Interaction applications over voice, bots, (RPA), AR/VR is a plus \n",
      "Experience in building robust data pipelines and familiarity with ETL/Data Wrangling tools Experience working in a cloud environment (AWS, Azure, GCP) or a containerized environment (Mesos, Kubernetes)\n",
      "Good understanding of reinforcement learning, graphical models, HMM and/or deep learning methods\n",
      "Experience with large data sets and distributed computing\n",
      "Experience with Spark or Map Reduce, SQL and noSQL databases\n",
      "Exposure to AWS/Azure is a plus\n",
      "Knowledge of statistics and experience using statistical packages for analyzing datasets (SAS, R, Python)\n",
      "Prior experience in BFSI domain and exposure to Big data, Hadoop, Scala, Pig, Hue, Hive etc. will be an added advantage, but not a requirement\n",
      "Exposure to modern Big Data tech: Cassandra/Scylla, Kafka, Ceph, the Hadoop Stack, Spark, Flume, Hive, Druid etc… while at the same time understanding that certain problems may require completely novel solutions\n",
      "Exposure to one or more modern ML tech stacks: Spark ML-Lib, Tensorflow, Keras, GCP ML Stack, AWS Sagemaker\n",
      "Deep technical understanding of Golang and/or Java\n",
      "Experience and proficiency with various programming languages (e.g., Python), machine learning tools (e.g., scikit-learn), \n",
      "statistical packages (e.g., Scipy), SQL/relational databases (e.g., Oracle) and NoSQL databass (e.g., MongoDB, graph database), Linux and shell scripting\n",
      "Advanced knowledge of machine learning, probability theory, statistics and algorithms.\n",
      "Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices\n",
      "Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData\n",
      "Strong understanding of Statistics.\n",
      "Experience working with or for Financial Institution in area like Fraud detection / Risk modelling / UW modelling etc. is highly desired\n",
      "Knowledge of Pythons data analysis and machine learning libraries a strong plus; Have experience/knowledge in SparkML and PySpark\n",
      "NLP & Text Mining Experience is a big plus.\n",
      "Knowledge of Big Data architectures a strong plus; Have basic knowledge in big data (storage and processing) tools like Hadoop, Hive, Spark and etc.\n",
      "Deliver on projects which require running a variety of statistical models for Marketing Mix, Pricing analytics , assortment and various such projects for Manufacturers and retailers\n",
      "Leverage Machine Learning techniques in analytics solutions to improve the predictive capability of models\n",
      "Execute approaches to analyze variety of datasets around sales and customer level purchase information, primarily running Regression, Cluster analysis, text based mining, etc. types of analysis\n",
      "Advanced knowledge of statistical packages such as R or RStudio, Python, PySpark. Strong problem solving skills\n",
      "Advanced knowledge of statistical packages such as R or RStudio, Python, PySpark. Strong problem solving skills\n",
      "Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, \n",
      "sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods.\n",
      "Expertise in Data Mining, Data wrangling, and data munging using one or more of the most commonly used data science tools: R, Python, SAS, SPSS, Weka\n",
      "Knowledge and experience in Hadoop (Map Reduce paradigm) etc.\n",
      "Must be hands-on and must have worked on implementing machine learning and data mining algorithms.\n",
      "Additional Skills (optional) Scala, Spark, H2O,Mahout, Hive\n",
      "Product Knowledge: At least 3 of the following: o R, Python (Scikit-learn, numpy, etc), Weka,SAS, SPSS, MATLAB/Octave, Hadoop (Map Reduce programming).\n",
      "Knowledge in Search Engine: such as Elastic, Apache Lucene/Solr\n",
      "Knowledge of saga and thunk for handling asynchronous API calls • Good hands-on experience in Nodejs.\n",
      "Creating restful services \n",
      "Processing and optimization of the large volume of data connecting to different data sources like Teradata, MongoDB, Cassandra, SQL \n",
      "Hands-on experience with use of standard natural language processing libraries and machine learning libraries such as Tensorflow, Keras, NLTK, OpenNLP, Spacy, Sk-Learn, ML-Lib\n",
      "Experience in developing models using deep learning techniques and tools, such as TensorFlow, Keras, etc.\n",
      "Knowledge and experience with OpenCV, MKL, ITK, VTK, GPGPU, specifically CUDA.\n",
      "Excellent understanding of software engineering principles and design patterns.\n",
      "Excellent programming skills in either Python, Scala, or Java.\n",
      "In-depth understanding of data science and machine learning technologies and methodologies.\n",
      "Good working knowledge of high performance computing, parallel data processing, and big data stack, e.g. Spark and Hadoop/Yarn.\n",
      "Experience to one or more commercial / open source data warehouses or data analytics systems, e.g. Teradata, is a big plus.\n",
      "Experience to one or more NoSQL databases is a big plus.\n",
      "Hands-on experience in Cloud platforms, e.g. AWS, or containerization/ virtualization platforms, e.g. Docker/Kubernetes, is a big plus.\n",
      "Experience to any data science or machine learning platform, e.g. IBM Data Science Experience or Cloudera Data Science Workbench, is a big plus.\n",
      "You are highly proficient in Python, C/C , and SQL\n",
      "Solid technical knowledge in machine learning, deep learning, statistical algorithms, data mining, and data structures\n",
      "Working experience: Image and Video analytics, Deep Learning, Tensorflow\n",
      "Hands-on knowledge in model development and deployment, visualization, and dashboard creation\n",
      "Experiences in processing and analyzing both structured and unstructured data\n",
      "Solid knowledge of big data processing framework and tools, such as Spark, Hadoop, MapReduce, etc.\n",
      "Proficiency in one or more programming languages including but not limited to: Python, Java, Scala, R\n",
      "Experience with SAS, SPSS, Python, R, Hadoop or SQL an advantage\n",
      "Experience in data mining, data analysis, model building, statistical modeling, predictive analytics and machine learning algorithms\n",
      "Experience building predictive models and implementation\n",
      "Experience with databases in general (more so the newer NoSQL DBs) and visualization tools (such as QlikView, Tableau etc ).\n",
      "Preferred experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms (including tools such as R)\n",
      "Good to have knowledge of Business Intelligence Tools such as KNIME, Tableau, Spotfire\n",
      "Good to have knowledge of Artificial Intelligence / Big Data Ecosystem such as Hadoop, Spark, TensorFlow, Hive\n",
      "Good to have knowledge of Scientific Computing such as C , Java, Scala\n",
      "Good to have knowledge of advanced analytical models such as Bayesian, Optimization (global, local, stochastic methods), Uncertainty Quantification, etc\n",
      "Fluency in C and Python\n",
      "Understanding of CNN basics\n",
      "Experience training CNN models on Caffe and Tensorflow\n",
      "Familiarity with state-of-the-art deep learning approaches\n",
      "Good knowledge in Computer Vision/OpenCV\n",
      "Demonstrated expertise in building deep learning models such as CNN, RNN, LSTM and GANs.\n",
      "Working knowledge of waveform/timeseries\n",
      "Strong implementation experience with a variety of high-level languages and frameworks such as Python, TensorFlow, Keras, Caffe, CNTK, etc.\n",
      "Min 8 years proven experience in modern machine learning, including deep learning\n",
      "Experience using machine learning toolboxes (e.g. Caffe, TensorFlow, or PyTorch).\n",
      "Experience in deep networks (CNN, DBN, RNN, LSTM, DCN) or reinforcement learning (RL).\n",
      "Proficient in Python and OOP development as well as in designing and implementing ML / deep learning network.\n",
      "Experience with classification and regression algorithms (e.g. SVM, MLP).\n",
      "Classification (logistic regression, svm, decision tree, random forest, neural network)\n",
      "Regression (linear regression, decision tree, random forest, neural network)\n",
      "Classical optimisation (gradient descent, newton rapshon, etc)\n",
      "Graph theory (network analytics)\n",
      "Heuristic optimisation (genetic algorithm, swarm theory)\n",
      "Deep leaning (lstm, convolutional nn, recurrent nn)\n",
      "Deep knowledge of fundamentals of AI, Machine / Deep Learning, Data Mining and Predictive Modelling is required with solid experience in applying these techniques on real world problems\n",
      "Interdisciplinary skills in Big Data Technologies, ETL, statistics and causal inference is desirable.\n",
      "Strong skills in software engineering practices (Design, Development and Requirement Management) with expertise in applicable programming languages and frameworks such as scikit-learn, XGBoost, Pytorch, Tensorflow, Spacy, H2O.\n",
      "Solid understanding of at least on the topics like deep learning, machine visions, NLP, knowledge graphs etc.\n",
      "Programming skills: python (must), MATLAB, R\n",
      "Understanding of cloud environment (AWS or Azure), containerization\n",
      "Ability to write production-quality object-oriented code in at least one of the following programming languages: Python, Java, C , Scala or C#;\n",
      "An open mind; desire to learn the best language/technology to solve a given problem;\n",
      "Deep understanding of machine learning theory and practice (feature engineering, regularization, hyperparameter tuning, ensemble methods, CNNs and RNNs);\n",
      "Expertise in data analysis (experiment design, classification, regression, unsupervised methods);\n",
      "Knowledge of core computer science concepts such as: data structures and algorithms, code profiling/optimization.\n",
      "Detailed knowledge of at least one popular Deep Learning library, proven ability to implement in practice any neural network configuration described in literature.\n",
      "Proficiency with regular expressions and other deterministic methods for processing text as well as experience in practical NLP is a plus;\n",
      "Deep understanding of cutting edge machine learning principles and techniques (CNN, learning rates, fast.ai, DL based NLP)\n",
      "Expertise with Python and machine learning libraries (Numpy, Tensorflow)\n",
      "Effective analytical presentation skills using living Jupyter notebooks and static presentation formats\n",
      "Deep knowledge of math, probability, statistics and algorithms.\n",
      "Outstanding analytical and problem-solving skills.\n",
      "In depth knowledge of Python, R, Java.\n",
      "Good understanding of tools such as Tensorflow, Matlab, Big Data Machine learning libraries like Apache Spark, Apache Flink, Azure Machine learning.\n",
      "Strong background in data structures and algorithms.\n",
      "Knowledge of SQL is a critical requirement.\n",
      "Working knowledge of Python or R (preferably Python)\n",
      "Data Science and Machine how to implement all them in Python or R. Ability to demonstrate this. The person should have worked on some projects in each of the areas related to Data Science and Machine Learning. If the person is able to share any Git repositories it would be good.\n",
      "Visualization exposure with knowledge of creating visualization using Python, D3.js, Power BI or Tableau (any one or two). More focus would be given to which visualizations to be used in different contexts and more importantly how to interpret them\n",
      "The candidate should have excellent knowledge on how to clean data (wrangling), transform and engineer data and interpret data relationships before even venturing into Machine Learning. A demonstrated ability to do this using any of the huge range of tools (both code based like Python) or non-code based.\n",
      "If the candidate has worked on any GUI based ML building tools like Azure ML Studio, AWS Sagemaker or Google Cloud Machine Learning Engine with projects the candidate will be able to publish : then it will be good.\n",
      "Should have developed solutions on Classification, Regression and Clustering based algorithms\n",
      "High proficiency in utilizing complex SQL queries for data analysis (SQLServer, DB2, Netezza, Hadoop/Hive) is required.\n",
      "Knowledge of big data tools/techniques (Hadoop, Hive,Map/Reduce, NoSQL) is required\n",
      "Demonstrated willingness to perform data analysis, data wrangling and ability to abstract rules for data store and processing. Experience with large data sets is required.\n",
      "Strong experience with analytical modeling techniques including Association, Classification, Clustering, Regression, Time Series Analysis, Text Analysis, Statistical analysis\n",
      "Experience with Data Visualization techniques is required\n",
      "Experience with image processing, text analytics is required. \n",
      "Ability to write production-quality object-oriented code in at least one of the following programming languages: Python, Java, C++, Scala or C#;\n",
      "An open mind; desire to learn the best language/technology to solve a given problem;\n",
      "Deep understanding of machine learning theory and practice (feature engineering, regularization, hyperparameter tuning, ensemble methods, CNNs and RNNs);\n",
      "Expertise in data analysis (experiment design, classification, regression, unsupervised methods);\n",
      "Knowledge of core computer science concepts such as: data structures and algorithms, code profiling/optimization.\n",
      "Detailed knowledge of at least one popular Deep Learning library, proven ability to implement in practice any neural network configuration described in literature.\n",
      "Proficiency with regular expressions and other deterministic methods for processing text as well as experience in practical NLP is a plus;\n",
      "Ease with Linux;\n",
      "Overall 6 years of experience with min 2 years of experience in Data Science, developing applications using Python, R, PySpark or Scala.\n",
      "Experience in various statistical and machine learning models, data mining, unstructured data, predictive and prescriptive analytics approaches. Experience in Text Mining/ NLP is a must\n",
      "Exceptional coding skills in Python, R, PySpark or Scala.\n",
      "Experience with Spark MLlib, deep-learning libraries, TensorFlow etc would be plus.\n",
      "Experience using Hadoop components such as Hive, Sqoop, Hbase, etc is a must.\n",
      "Understanding Python integration with django, flask and REST API.\n",
      "Familiarity with data visualization libraries in Python, R or tools such as Tableau, PowerBI.\n",
      "Identify, analyze, and interpret trends or patterns in complex data sets.\n",
      "Experience with Natural language processing is highly preferred.\n",
      "Expert-level knowledge in learning algorithms such as inverse reinforcement learning, deep reinforcement learning and probabilistic inference for decision support systems \n",
      "Knowledge and hands-on expertise in deep neural network topologies such as convolutional nets, recurrent nets, RBMs, causal reasoning, probabilistic programming \n",
      "Mathematically minded with experience in manipulating high-volume, high-dimensionality data from varying sources to highlight patterns, anomalies, relationships and trends with machine learning techniques \n",
      "2+ years of experience with Machine Learning, Statistical Models, and Natural Language Processing \n",
      "Experience with Python, TensorFlow, Keras, StackStorm\n",
      "Solid understanding of Data Structures, Algorithms & Object-Oriented design concepts \n",
      "Deep understanding of statistical modelling, machine learning, or data mining, text mining concepts and a track record of solving problems with these methods.\n",
      "Proficient in tools such as R/SAS/SPSS/Phyton.\n",
      "Excellent communication, relationship skills and a strong team player.\n",
      "Experience in big data techniques (such as Hadoop, MapReduce, Hive, Pig, and Spark), deep learning, and any BI/Visualisation tool (such as OBIEE, Tableau, and D3.js) is a plus.\n",
      "Knowledge of a variety of quantitative modeling techniques, e.g., logistic regression, decision trees, SVMs, neural networks, graph theory\n",
      "Solid visualization skills\n",
      "Previous experience working with time series, trajectories and GIS datasets\n",
      "Competence in writing code in statistical programming languages or frameworks (e.g., R, Weka, etc.)\n",
      "Proven Data science experience in Retail Space – Strongly preferred\n",
      "Working experience with Assortment Optimization in retail/e-commerce\n",
      "Experience with discrete choice modelling: \n",
      "Multinomial Logit Model, Nested / Mixed Logit Model, Exogenous Demand Model\n",
      "Experience with modelling substitution and cannibalization effects\n",
      "Experience with optimization algorithms\n",
      "Experience with Python.\n",
      "Experience with relational databases such as NoSQL or MongoDB.\n",
      "Minimum 4 years’ experience with large amounts of real data.\n",
      "Minimum 2 years’ experience leading project teams on relevant engagements.\n",
      "Experience in Hadoop, Spark, Storm or related paradigms and associated languages such as Pig, Hive, Mahout, plus advanced skills in Java/C++, R, etc.\n",
      "Ability to communicate complex quantitative analysis in a concise and actionable manner.\n",
      "Proficient in manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources.\n",
      "Extensive knowledge of tools for data mining and statistics (SAS, SPSS, MATLAB).\n",
      "Ability to work independently and manage multiple task assignments.\n",
      "Strong oral and written communication skills, including presentation skill.\n",
      "Strong competency in various machine learning techniques (supervised learning, unsupervised learning, reinforcement learning).\n",
      "Strong knowledge of other quantitative disciplines (operations research, decision theory, etc.). Knowledge of machine to machine learning techniques.\n",
      "Solid understanding of advanced analytics (statistics, simulation, optimizations, etc.).\n",
      "Proven background in at least one of the following - Reliability models, Markov Models, Stochastic models, Bayesian Modeling, Classification Models, Cluster Analysis, Neural Network, Non-parametric Methods, Multivariate Statistics\n",
      "Experience working with large data sets and tools like MapReduce, Hadoop, Hive, etc.\n",
      "Experience working with large data streaming technologies like Spark, Flink, etc.\n",
      "Extract data from Bigquery and build models to identify key factors impacting retention, monetization and engagement metrics.\n",
      "Identifying the appropriate univariate and multivariate analysis to identify key customer trends and insights - Segmentation, Logistic regression, Decision Trees, Factor analysis, etc.\n",
      "Experience in analytical methods (like Classification, decision trees, ANOVA, feature engineering, regression, forecasting, Machine Learning Techniques, etc.)\n",
      "Very good coding skills in any of these languages: R, Python, Matlab, Java, C and Machine Learning libraries like scipy, numpy, pyspark, tensorflow etc\n",
      "Basic knowledge of Big Data stack: Spark, Cassandra, Map-Reduce, S3\n",
      "2+ years of experience with Python or R and some knowledge of SQL. \n",
      "Experience with other software environments e.g. SAS, Matlab, Spotfire, Tableau, Qlikview, SPSS, KNIME and/or other data mining software is a plus. \n",
      "Mixed Integer Linear Programming, Conic Integer Optimization, Greedy and Interchange heuristics\n",
      "Python, scrapy, selenium, requests, beautifulsoup, mechanize, lxml, urllib2, web scraping, web crawling, automation, bots, scrapers, spiders\n",
      "Solid engineering and coding skills. And the ability to write high performance production code. Experience in Go, Python Scala and other equivalent language is a plus.\n",
      "Experience with MapReduce, Spark and Hive is a plus.\n",
      "Build and deploy scalable machine learning models to enable our fraud, risk and safety systems.\n",
      "Analyze data and define metrics for feature evaluation and model performance.\n",
      "Design and implement robust data pipelines.\n",
      "Proficient in RDBMS such as PostgresQL or MySQL; and statistical programming in languages like R, Python, Java, C++ or SAS\n",
      "Experience in ETL, feature selections, modeling, model validation and conducting data analyses using R, SQL, Python or any JVM languages\n",
      "Strong understanding and implementation experience of predictive modeling algorithms such as logistic regression, neural networks, forward propagation, decision trees and heuristic models, with familiarity dealing with trade offs between model performance and business needs\n",
      "Good understanding of the fraud space with hands-on knowledge of fraud, payments and risk, especially on tech products\n",
      "Experience in geospatial databases or graph databases\n",
      "Recent programming experience in a production environment\n",
      "Experience in Scala or PySpark on distributed systems\n",
      "Interest in working with MapReduce technologies (such as Hadoop / Spark)\n",
      "Familiarity with Python Scikit Learn, Panda or Spark ML/Mllib is a plus\n",
      "Knowledge of Statistical methods, Probabilities and Distribution, Sampling Distribution central limit theorem, confidence intervals, hypothesis testing, variances, Linear Regression, ANOVA, Exploratory data Analysis…\n",
      "Machine Learning model implementation experience on one or more of – Classification models (e.g. Support Vector Machines, Discriminant Analysis, Bayes network, Nearest neighbor…), Regression models (e.g. Linear regression, GLM, SVR, GPR, Ensemble methods, Decision trees, Neural Networks..), Clustering models (e.g. K-means, Fuzzy C-Means, Hierarchical, Gaussian, Hidden Markov Model..)\n",
      "Knowledge or working experience of Artificial Intelligence system on one or more of  Case-based reasoning systems, rule-based systems, artificial neural networks, cellular automata, fuzzy models, genetic algorithms, multi-agent systems, reinforced learning, hybrid systems..\n",
      "Working knowledge of Data engineering - Big Data, Hadoop, Cassandra, Spark R, RDBMS DB SQL, N-SQL DB, Big-Query, Documents stores etc. Hands-on experience preferred\n",
      "Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\n",
      "Experience with common data science toolkits, such as R, NumPy, OpenCV, MatLab, etc\n",
      "Great communication skills\n",
      "Experience with data visualisation tools, such as D3.js, GGplot, etc.\n",
      "Experience with NoSQL databases, such as MongoDB, Cassandra, HBase {{depending on project needs}}\n",
      "Good applied statistics skills, such as distributions, statistical testing, regression, etc.\n",
      "SPSS, SAS, Matlab, KNIME etc.\n",
      "R, Python etc.\n",
      "Hadoop, Hortonworks, Cloudera, IBM Big Insights etc.\n",
      "Mapreduce, Spark, Mahout etc.\n",
      "SQL/noSQL Databases and its manipulation components\n",
      "Additionally, the following will be considered a strong asset:\n",
      "Software development experiences in Java and/or C/C++ as well as advanced databases.\n",
      "Iulia Z\n",
      "- Core technique on audio processing\n",
      "Significant achievement on offline NLP engines with the help of deep learning.\n",
      "Application areas include automatic speech recognition, speech synthesis, sound classification, adaptive noise cancellation, neural voice cloning, chat bot, NMT.\n",
      "- Image processing with various DNN models such as YOLO, Fast R-CNN, Mask R-CNN, Google Inception V3, Resnet, Alexnet, Vgg16... as well as traditional algorithms and OpenCV\n",
      "Developed amazing offline engines in ALPR, OCR, Face detection & recognition, Facial expression change, Object detection, tracking, counting.\n",
      "Boris Banushev\n",
      "1. Selected experience:\n",
      "- Developed and backtested AI and ML quantitative trading algos using deep learning (RNN, DCGAN, VAE);\n",
      "- Creating optimal stock portfolio allocation using Reinforcement learning;\n",
      "- Retail banking merchant/client expansion strategy using network science theory (+ ERGMs and NetworkX), recommender systems, and GraphDB (Azure Cosmos and native Gremlin queries);\n",
      "- Real time fraud detection using generative models and deep unsupervised learning (SOM, RBM).\n",
      "- Built end-to-end AI/ML CICD platform;\n",
      "- Led Investor negotiations and fundraising;\n",
      "- Run boutique stock market broker and ultimately sold it for 450x ROI;\n",
      "- Participated in IPO, M&A, and corporate valuation and due diligence;\n",
      "2. Tech skills:\n",
      "- Deep Reinforcement Learning;\n",
      "- RNN (LSTM, GRU, built own cell);\n",
      "- CNN, transfer learning, (VAE)GAN, DCGAN;\n",
      "- XGBoost, PCA, tSNE, LDA, sklearn;\n",
      "- Unsupervised (RBM, SOM, SVM);\n",
      "- AWS SageMaker + BYOModel;\n",
      "- Modifications on keras, pytorch, tf;\n",
      "- python (pandas, numpy, scipy);\n",
      "- Hyper-parameter optimisation using Reinforcement Learning;\n",
      "- AI/ML model training and deployment CI/CD (AWS, Azure);\n",
      "- Complete understanding of the whole math behind all ML;\n",
      "- Graph DB, NoSQL;\n",
      "- Serverless architecture - AWS Lambda, Azure Functions;\n",
      "- The whole AWS and Azure ecosystems;\n",
      "- Hadoop, HIVE, pySpark, Docker, Kubernetes;\n",
      "Natural language processing (NLP): This includes topic modelling, word embeddings, document embeddings, sentiment analysis, \n",
      "LSTM, RNN, GRU, word2vec, doc2vec, GloVe, fastText, BERT, ELMO, attention models, transformers etc.\n",
      "Excellent knowledge of C/C++\n",
      "Experience with Linux and multithreading.\n",
      "Good knowledge and experience in Computer Vision(Object  detection, Segmentation)  and  Machine  Learning, an advantage\n",
      "ARM experience an advantage\n",
      "GPU Programming  using  Cuda  or  OpenCL, an advantage\n",
      "SIMD (AVX/NEON) an advantage\n",
      "NLP:\n",
      "Demonstrated experience in application of NLP algorithms for matching & retrieval, clustering, generating ontologies, \n",
      "machine translation, concept extraction, entity extraction\n",
      "Experience in Big data technologies such as Spark, Cassandra, HDFS, Kafka, Druid, Elastic Stack, Hive, HBase etc. in a complex Big Data product/project\n",
      "1)     Deep Learning (CNNs/RNNs, Reinforcement Learning, VAEs/GANs)\n",
      "2)     Machine Learning (Regression, Random Forests, SVMs, K-means, ensemble methods)\n",
      "3)     Natural Language Processing\n",
      "4)     Graph Databases (Neo4j, Apache Giraph)\n",
      "5)     Azure Bot Service\n",
      "6)     Azure ML Studio / Azure Cognitive Services\n",
      "7)     Log Analytics with NLP/ML/DL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contents = contents.replace('.','')\n",
    "contents = contents.replace('’','')\n",
    "contents = contents.replace(',','')\n",
    "contents = contents.replace('–','')\n",
    "contents = contents.replace('-','')\n",
    "contents = contents.replace('(','')\n",
    "contents = contents.replace(')','')\n",
    "contents = contents.replace('/',' ')\n",
    "contents = contents.replace(':',' ')\n",
    "contents = contents.replace('&',' ')\n",
    "contents = contents.replace('+',' ')\n",
    "contents = contents.replace('1',' ')\n",
    "contents = contents.replace('2',' ')\n",
    "contents = contents.replace('3',' ')\n",
    "contents = contents.replace('4',' ')\n",
    "contents = contents.replace('5',' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contents = contents.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"you will be researching developing and implementing deep learning frameworks keras tensorflow pytorch mxnet etc \\npython or c   and caffe tensorflow pytorch etc\\nexperience with distributed data computing tools  map reduce hadoop hive spark dockers mysql etc\\nexperience visualizing presenting data for stakeholders using  tableau high charts d  gg plot etc\\nhighly proficient in languages and tools used in ml modeling like r python scikit learn scipy numpy etc \\napache spark scala or python h o weka tensorflow torch keras\\nhighly proficient in languages and tools used in ml modeling like r python scikit learn scipy numpy etc \\napache spark scala or python h o weka tensorflow torch keras\\npreferred handson experience in coding in c c   java scala or any other\\npreferred experience in big data tools like hadoop pig hive mapreduce or any other\\nprior experience with big data platforms tools hadoop mongodb cassandra etc \\nworking proficiency in at least one data mining tool sas spss r rapidminer etc\\nprior experience with big\\n   years design implementation consulting experience training machine learning models and deploying scoring pipelines at scale\\n   years professional experience in software development in languages like java python scala \\nhave worked and deployed on technologies such as aws azure google cloud hadoop rdbms mongodb nosql and or hive\\nhave experience with etl nlp ai ml and or dp will be advantageous\\nexperience with mapreduce hadoop and related technologies eg pig hive cascading\\nfamiliarity with amazon web services and elastic mapreduce a plus\\nfamiliarity with hadoop based commercial packages eg cloudera hortonworks\\nexperience in text mining nlp\\nexperience with python or c   programming language\\nexperience working with restful api and general service oriented architectures\\nexperience managing teams of data scientists machine learning engineers software engineers and or consultants \\nan exceptional data modelling background with experience across one or more of the following tools r python spss matlab\\nbuild products alongside the core engineering team and evolve the engineering process to scale with data handling complex problems and advanced client situations\\nbe able to focus on modelling by working alongside the data engineering team which focuses on the wrangling cleanup and transformation of data\\ndeep understanding on feature selection and modelling familiar with the theories behind common models logistic regression random forest boosting trees neural network etc and experienced in finetuning\\nfamiliar with apache spark\\nexperience using robotics frameworks rpa software products like blue prism uipath automation anywhere kofax etc\\nprofessional knowledge of machine learning environments such as regression or decision trees or random forest or deep learning\\nexperience designing and deploying with one or more the technologies like tensor flow spark ml cntk torch caffe\\nknowledge of big data technologies such as spark hadoop cornerstone is highly desirable\\ngood knowledge of databases like sql postgresql mongo redis cassandra\\nexposure to node   scala is desirableproficient in python and related data processing libraries such as pandas and numpy\\nsolid coding skills in python r java mysql nosql\\nfamiliar with deep learning topologies\\nexperience with cloud platforms such as gcp\\ndata pipeline skills  spark celery jinja\\nprofessional experience with cloud native architectures and design specifically aws services such as s  lambda ec  rds postgres api gateway ecr and fargate\\nexperience building continuous integration pipelines for containerized machine learning models\\nexperience in geospatial geolocation analysis and neural networks\\ncomfortable with devops and infrastructure technologies such as terraform circleci docker and the serverless framework\\ndevelop scalable tools leveraging machine learning and deep learning models to solve realworld problems in areas such as speech recognition natural language processing and time series predictions\\ncollaborate with all of jpmorgan chase's lines of businesses such as investment bank commercial bank and asset managementlead your own project \\nsuggest collect and synthesize requirements \\ncreate an effective roadmap towards the deployment of a productionlevel machine learning application\\nms or phd in a quantitative discipline eg computer science mathematics operations research data science or similar bs with    years of experience in a highly quantitative position\\nexperience in deep learning  dnn cnn rnn lstm gan or other auto encoder ae\\n   years of handson experience developing machine learning models\\nability to develop and debug in python java c or c   \\nproficient in git version control r and matlab are also relevant\\nextensive experience with machine learning apis and computational packages tensorflow theano pytorch keras scikitlearn numpy scipy pandas statsmodels\\nfamiliarity with generation of heatmaps and biplots a plus\\nbest practices in software development and productionise machine learning by working with our machine learning engineering teams which optimise code for model development and scale it\\nwork with our ux and visual design teams to interpret your complex models into stunning and userfocused visualisations\\na strong understanding of data engineering and ingestion with experience across a range of datastores that could include hadoop spark teradata aws redshift mpp greenplum oracle mongodb sql cassandra\\nstrong data visualisation skills across qlikview and or tableau\\nmasters or phd in an analytical or technical field  mathematics statistics computer science physics or engineering\\nminimum   years working experience manipulating data sets and building statistical models has a masters in statistics mathematics computer science or another quantitative field and is familiar with the software tools\\nexperience with machine and deep learning toolkits such as mxnet tensorflow caffe and torch\\nexperience with big data platforms like apache spark and hadoop\\nexperienced in data processing with python r   sql\\nexperience with aws services related to ai ml highly desirable particularly amazon emr aws lambda sagemaker machine learning iot amazon dynamodb amazon s  amazon ec  container service green grass etc\\nexperience with sas spss python r hadoop or sql an advantage\\nexperience with databases in general more so the newer nosql dbs and visualization tools such as qlikview tableau etc \\npreferred experience with a wide variety of predictive modeling machine learning data mining statistical text mining and optimization algorithms including tools such as r\\nproficiency using r   python for predictive modelling pattern recognition and algorithm prototyping\\njava and or scala programming is a plus\\nextracting and transforming data from systems like hadoop and sql using tools such as pig scalding hive presto\\nsome experience with one or more object oriented languages like java scala c  \\nsome experience with scripting languages like python or ruby etc\\nsome experience with statistical programming environments like r or matlab\\nexperience with large datasets and map reduce architectures like hadoop and open source data mining and machine learning projects\\nexperience using sql analyzing datasets with databases such as presto teradata oracle and mysql\\nexperience using r python stata or other scripting languages for data prep analysis and machine learning\\nexperience with applied social science research or familiarity with publiclyavailable government data sets such as those provided by eurostat the office for national statistics uk insee france the world bank the un the bls and census bureau us and other national and international statistical agencies\\nfamiliarity with data visualization and or bi tools ex tableau powerbi\\nexperience with hadoop hive pig or mapreduce\\ndeep knowledge of some of the popular ml frameworks such as sparkml tensorflow scikitlearn xgboost h o etc \\nability to translate business problems into analytical structures and can be solved using statistical ml techniques\\nexpert proficiency in a structured programming language is a must  experience in at least one statistical general purpose scripting languages like r or python is mandatory\\nat least   years of relevant experience which should include handson programming in oneor more of the languages specified above\\nunderstanding of concepts to analyze text image video etc is a plus not mandatory\\nexperience with technologies such as spark ml tensorflow open cv caffe etc is a plusnot mandatory\\ndeep understanding of predictive modeling machinelearning clustering and classification techniques and algorithms\\nfluency in a programming language python r java sqlhadoopmldlnlp\\nfamiliarity with big data frameworks and visualization tools cassandra hadooppighive spark tableau\\nexperience in building large scale distributed ml models experience in building modern machine learning platforms a big plus\\nexperience with human computer interaction applications over voice bots rpa ar vr is a plus \\nexperience in building robust data pipelines and familiarity with etl data wrangling tools experience working in a cloud environment aws azure gcp or a containerized environment mesos kubernetes\\ngood understanding of reinforcement learning graphical models hmm and or deep learning methods\\nexperience with large data sets and distributed computing\\nexperience with spark or map reduce sql and nosql databases\\nexposure to aws azure is a plus\\nknowledge of statistics and experience using statistical packages for analyzing datasets sas r python\\nprior experience in bfsi domain and exposure to big data hadoop scala pig hue hive etc will be an added advantage but not a requirement\\nexposure to modern big data tech  cassandra scylla kafka ceph the hadoop stack spark flume hive druid etc… while at the same time understanding that certain problems may require completely novel solutions\\nexposure to one or more modern ml tech stacks  spark mllib tensorflow keras gcp ml stack aws sagemaker\\ndeep technical understanding of golang and or java\\nexperience and proficiency with various programming languages eg python machine learning tools eg scikitlearn \\nstatistical packages eg scipy sql relational databases eg oracle and nosql databass eg mongodb graph database linux and shell scripting\\nadvanced knowledge of machine learning probability theory statistics and algorithms\\nlead data science and machine learning efforts in products and solutions involving iot big data cloud and microservices\\nexperience in spark mllib pyspark numpy scipy tidydata\\nstrong understanding of statistics\\nexperience working with or for financial institution in area like fraud detection   risk modelling   uw modelling etc is highly desired\\nknowledge of pythons data analysis and machine learning libraries a strong plus; have experience knowledge in sparkml and pyspark\\nnlp   text mining experience is a big plus\\nknowledge of big data architectures a strong plus; have basic knowledge in big data storage and processing tools like hadoop hive spark and etc\\ndeliver on projects which require running a variety of statistical models for marketing mix pricing analytics  assortment and various such projects for manufacturers and retailers\\nleverage machine learning techniques in analytics solutions to improve the predictive capability of models\\nexecute approaches to analyze variety of datasets around sales and customer level purchase information primarily running regression cluster analysis text based mining etc types of analysis\\nadvanced knowledge of statistical packages such as r or rstudio python pyspark strong problem solving skills\\nadvanced knowledge of statistical packages such as r or rstudio python pyspark strong problem solving skills\\nperform machine learning text analytics and statistical analysis methods such as classification collaborative filtering association rules \\nsentiment analysis topic modeling timeseries analysis regression statistical inference and validation methods\\nexpertise in data mining data wrangling and data munging using one or more of the most commonly used data science tools  r python sas spss weka\\nknowledge and experience in hadoop map reduce paradigm etc\\nmust be handson and must have worked on implementing machine learning and data mining algorithms\\nadditional skills optional scala spark h omahout hive\\nproduct knowledge  at least   of the following  o r python scikitlearn numpy etc wekasas spss matlab octave hadoop map reduce programming\\nknowledge in search engine  such as elastic apache lucene solr\\nknowledge of saga and thunk for handling asynchronous api calls • good handson experience in nodejs\\ncreating restful services \\nprocessing and optimization of the large volume of data connecting to different data sources like teradata mongodb cassandra sql \\nhandson experience with use of standard natural language processing libraries and machine learning libraries such as tensorflow keras nltk opennlp spacy sklearn mllib\\nexperience in developing models using deep learning techniques and tools such as tensorflow keras etc\\nknowledge and experience with opencv mkl itk vtk gpgpu specifically cuda\\nexcellent understanding of software engineering principles and design patterns\\nexcellent programming skills in either python scala or java\\nindepth understanding of data science and machine learning technologies and methodologies\\ngood working knowledge of high performance computing parallel data processing and big data stack eg spark and hadoop yarn\\nexperience to one or more commercial   open source data warehouses or data analytics systems eg teradata is a big plus\\nexperience to one or more nosql databases is a big plus\\nhandson experience in cloud platforms eg aws or containerization  virtualization platforms eg docker kubernetes is a big plus\\nexperience to any data science or machine learning platform eg ibm data science experience or cloudera data science workbench is a big plus\\nyou are highly proficient in python c c  and sql\\nsolid technical knowledge in machine learning deep learning statistical algorithms data mining and data structures\\nworking experience  image and video analytics deep learning tensorflow\\nhandson knowledge in model development and deployment visualization and dashboard creation\\nexperiences in processing and analyzing both structured and unstructured data\\nsolid knowledge of big data processing framework and tools such as spark hadoop mapreduce etc\\nproficiency in one or more programming languages including but not limited to  python java scala r\\nexperience with sas spss python r hadoop or sql an advantage\\nexperience in data mining data analysis model building statistical modeling predictive analytics and machine learning algorithms\\nexperience building predictive models and implementation\\nexperience with databases in general more so the newer nosql dbs and visualization tools such as qlikview tableau etc \\npreferred experience with a wide variety of predictive modeling machine learning data mining statistical text mining and optimization algorithms including tools such as r\\ngood to have knowledge of business intelligence tools such as knime tableau spotfire\\ngood to have knowledge of artificial intelligence   big data ecosystem such as hadoop spark tensorflow hive\\ngood to have knowledge of scientific computing such as c  java scala\\ngood to have knowledge of advanced analytical models such as bayesian optimization global local stochastic methods uncertainty quantification etc\\nfluency in c and python\\nunderstanding of cnn basics\\nexperience training cnn models on caffe and tensorflow\\nfamiliarity with stateoftheart deep learning approaches\\ngood knowledge in computer vision opencv\\ndemonstrated expertise in building deep learning models such as cnn rnn lstm and gans\\nworking knowledge of waveform timeseries\\nstrong implementation experience with a variety of highlevel languages and frameworks such as python tensorflow keras caffe cntk etc\\nmin 8 years proven experience in modern machine learning including deep learning\\nexperience using machine learning toolboxes eg caffe tensorflow or pytorch\\nexperience in deep networks cnn dbn rnn lstm dcn or reinforcement learning rl\\nproficient in python and oop development as well as in designing and implementing ml   deep learning network\\nexperience with classification and regression algorithms eg svm mlp\\nclassification logistic regression svm decision tree random forest neural network\\nregression linear regression decision tree random forest neural network\\nclassical optimisation gradient descent newton rapshon etc\\ngraph theory network analytics\\nheuristic optimisation genetic algorithm swarm theory\\ndeep leaning lstm convolutional nn recurrent nn\\ndeep knowledge of fundamentals of ai machine   deep learning data mining and predictive modelling is required with solid experience in applying these techniques on real world problems\\ninterdisciplinary skills in big data technologies etl statistics and causal inference is desirable\\nstrong skills in software engineering practices design development and requirement management with expertise in applicable programming languages and frameworks such as scikitlearn xgboost pytorch tensorflow spacy h o\\nsolid understanding of at least on the topics like deep learning machine visions nlp knowledge graphs etc\\nprogramming skills  python must matlab r\\nunderstanding of cloud environment aws or azure containerization\\nability to write productionquality objectoriented code in at least one of the following programming languages  python java c  scala or c#;\\nan open mind; desire to learn the best language technology to solve a given problem;\\ndeep understanding of machine learning theory and practice feature engineering regularization hyperparameter tuning ensemble methods cnns and rnns;\\nexpertise in data analysis experiment design classification regression unsupervised methods;\\nknowledge of core computer science concepts such as  data structures and algorithms code profiling optimization\\ndetailed knowledge of at least one popular deep learning library proven ability to implement in practice any neural network configuration described in literature\\nproficiency with regular expressions and other deterministic methods for processing text as well as experience in practical nlp is a plus;\\ndeep understanding of cutting edge machine learning principles and techniques cnn learning rates fastai dl based nlp\\nexpertise with python and machine learning libraries numpy tensorflow\\neffective analytical presentation skills using living jupyter notebooks and static presentation formats\\ndeep knowledge of math probability statistics and algorithms\\noutstanding analytical and problemsolving skills\\nin depth knowledge of python r java\\ngood understanding of tools such as tensorflow matlab big data machine learning libraries like apache spark apache flink azure machine learning\\nstrong background in data structures and algorithms\\nknowledge of sql is a critical requirement\\nworking knowledge of python or r preferably python\\ndata science and machine how to implement all them in python or r ability to demonstrate this the person should have worked on some projects in each of the areas related to data science and machine learning if the person is able to share any git repositories it would be good\\nvisualization exposure with knowledge of creating visualization using python d js power bi or tableau any one or two more focus would be given to which visualizations to be used in different contexts and more importantly how to interpret them\\nthe candidate should have excellent knowledge on how to clean data wrangling transform and engineer data and interpret data relationships before even venturing into machine learning a demonstrated ability to do this using any of the huge range of tools both code based like python or noncode based\\nif the candidate has worked on any gui based ml building tools like azure ml studio aws sagemaker or google cloud machine learning engine with projects the candidate will be able to publish   then it will be good\\nshould have developed solutions on classification regression and clustering based algorithms\\nhigh proficiency in utilizing complex sql queries for data analysis sqlserver db  netezza hadoop hive is required\\nknowledge of big data tools techniques hadoop hivemap reduce nosql is required\\ndemonstrated willingness to perform data analysis data wrangling and ability to abstract rules for data store and processing experience with large data sets is required\\nstrong experience with analytical modeling techniques including association classification clustering regression time series analysis text analysis statistical analysis\\nexperience with data visualization techniques is required\\nexperience with image processing text analytics is required \\nability to write productionquality objectoriented code in at least one of the following programming languages  python java c   scala or c#;\\nan open mind; desire to learn the best language technology to solve a given problem;\\ndeep understanding of machine learning theory and practice feature engineering regularization hyperparameter tuning ensemble methods cnns and rnns;\\nexpertise in data analysis experiment design classification regression unsupervised methods;\\nknowledge of core computer science concepts such as  data structures and algorithms code profiling optimization\\ndetailed knowledge of at least one popular deep learning library proven ability to implement in practice any neural network configuration described in literature\\nproficiency with regular expressions and other deterministic methods for processing text as well as experience in practical nlp is a plus;\\nease with linux;\\noverall 6 years of experience with min   years of experience in data science developing applications using python r pyspark or scala\\nexperience in various statistical and machine learning models data mining unstructured data predictive and prescriptive analytics approaches experience in text mining  nlp is a must\\nexceptional coding skills in python r pyspark or scala\\nexperience with spark mllib deeplearning libraries tensorflow etc would be plus\\nexperience using hadoop components such as hive sqoop hbase etc is a must\\nunderstanding python integration with django flask and rest api\\nfamiliarity with data visualization libraries in python r or tools such as tableau powerbi\\nidentify analyze and interpret trends or patterns in complex data sets\\nexperience with natural language processing is highly preferred\\nexpertlevel knowledge in learning algorithms such as inverse reinforcement learning deep reinforcement learning and probabilistic inference for decision support systems \\nknowledge and handson expertise in deep neural network topologies such as convolutional nets recurrent nets rbms causal reasoning probabilistic programming \\nmathematically minded with experience in manipulating highvolume highdimensionality data from varying sources to highlight patterns anomalies relationships and trends with machine learning techniques \\n   years of experience with machine learning statistical models and natural language processing \\nexperience with python tensorflow keras stackstorm\\nsolid understanding of data structures algorithms   objectoriented design concepts \\ndeep understanding of statistical modelling machine learning or data mining text mining concepts and a track record of solving problems with these methods\\nproficient in tools such as r sas spss phyton\\nexcellent communication relationship skills and a strong team player\\nexperience in big data techniques such as hadoop mapreduce hive pig and spark deep learning and any bi visualisation tool such as obiee tableau and d js is a plus\\nknowledge of a variety of quantitative modeling techniques eg logistic regression decision trees svms neural networks graph theory\\nsolid visualization skills\\nprevious experience working with time series trajectories and gis datasets\\ncompetence in writing code in statistical programming languages or frameworks eg r weka etc\\nproven data science experience in retail space  strongly preferred\\nworking experience with assortment optimization in retail ecommerce\\nexperience with discrete choice modelling  \\nmultinomial logit model nested   mixed logit model exogenous demand model\\nexperience with modelling substitution and cannibalization effects\\nexperience with optimization algorithms\\nexperience with python\\nexperience with relational databases such as nosql or mongodb\\nminimum   years experience with large amounts of real data\\nminimum   years experience leading project teams on relevant engagements\\nexperience in hadoop spark storm or related paradigms and associated languages such as pig hive mahout plus advanced skills in java c   r etc\\nability to communicate complex quantitative analysis in a concise and actionable manner\\nproficient in manipulating and analyzing complex highvolume highdimensionality data from varying sources\\nextensive knowledge of tools for data mining and statistics sas spss matlab\\nability to work independently and manage multiple task assignments\\nstrong oral and written communication skills including presentation skill\\nstrong competency in various machine learning techniques supervised learning unsupervised learning reinforcement learning\\nstrong knowledge of other quantitative disciplines operations research decision theory etc knowledge of machine to machine learning techniques\\nsolid understanding of advanced analytics statistics simulation optimizations etc\\nproven background in at least one of the following  reliability models markov models stochastic models bayesian modeling classification models cluster analysis neural network nonparametric methods multivariate statistics\\nexperience working with large data sets and tools like mapreduce hadoop hive etc\\nexperience working with large data streaming technologies like spark flink etc\\nextract data from bigquery and build models to identify key factors impacting retention monetization and engagement metrics\\nidentifying the appropriate univariate and multivariate analysis to identify key customer trends and insights  segmentation logistic regression decision trees factor analysis etc\\nexperience in analytical methods like classification decision trees anova feature engineering regression forecasting machine learning techniques etc\\nvery good coding skills in any of these languages  r python matlab java c and machine learning libraries like scipy numpy pyspark tensorflow etc\\nbasic knowledge of big data stack  spark cassandra mapreduce s \\n   years of experience with python or r and some knowledge of sql \\nexperience with other software environments eg sas matlab spotfire tableau qlikview spss knime and or other data mining software is a plus \\nmixed integer linear programming conic integer optimization greedy and interchange heuristics\\npython scrapy selenium requests beautifulsoup mechanize lxml urllib  web scraping web crawling automation bots scrapers spiders\\nsolid engineering and coding skills and the ability to write high performance production code experience in go python scala and other equivalent language is a plus\\nexperience with mapreduce spark and hive is a plus\\nbuild and deploy scalable machine learning models to enable our fraud risk and safety systems\\nanalyze data and define metrics for feature evaluation and model performance\\ndesign and implement robust data pipelines\\nproficient in rdbms such as postgresql or mysql; and statistical programming in languages like r python java c   or sas\\nexperience in etl feature selections modeling model validation and conducting data analyses using r sql python or any jvm languages\\nstrong understanding and implementation experience of predictive modeling algorithms such as logistic regression neural networks forward propagation decision trees and heuristic models with familiarity dealing with trade offs between model performance and business needs\\ngood understanding of the fraud space with handson knowledge of fraud payments and risk especially on tech products\\nexperience in geospatial databases or graph databases\\nrecent programming experience in a production environment\\nexperience in scala or pyspark on distributed systems\\ninterest in working with mapreduce technologies such as hadoop   spark\\nfamiliarity with python scikit learn panda or spark ml mllib is a plus\\nknowledge of statistical methods probabilities and distribution sampling distribution central limit theorem confidence intervals hypothesis testing variances linear regression anova exploratory data analysis…\\nmachine learning model implementation experience on one or more of  classification models eg support vector machines discriminant analysis bayes network nearest neighbor… regression models eg linear regression glm svr gpr ensemble methods decision trees neural networks clustering models eg kmeans fuzzy cmeans hierarchical gaussian hidden markov model\\nknowledge or working experience of artificial intelligence system on one or more of  casebased reasoning systems rulebased systems artificial neural networks cellular automata fuzzy models genetic algorithms multiagent systems reinforced learning hybrid systems\\nworking knowledge of data engineering  big data hadoop cassandra spark r rdbms db sql nsql db bigquery documents stores etc handson experience preferred\\nexcellent understanding of machine learning techniques and algorithms such as knn naive bayes svm decision forests etc\\nexperience with common data science toolkits such as r numpy opencv matlab etc\\ngreat communication skills\\nexperience with data visualisation tools such as d js ggplot etc\\nexperience with nosql databases such as mongodb cassandra hbase {{depending on project needs}}\\ngood applied statistics skills such as distributions statistical testing regression etc\\nspss sas matlab knime etc\\nr python etc\\nhadoop hortonworks cloudera ibm big insights etc\\nmapreduce spark mahout etc\\nsql nosql databases and its manipulation components\\nadditionally the following will be considered a strong asset \\nsoftware development experiences in java and or c c   as well as advanced databases\\niulia z\\n core technique on audio processing\\nsignificant achievement on offline nlp engines with the help of deep learning\\napplication areas include automatic speech recognition speech synthesis sound classification adaptive noise cancellation neural voice cloning chat bot nmt\\n image processing with various dnn models such as yolo fast rcnn mask rcnn google inception v  resnet alexnet vgg 6 as well as traditional algorithms and opencv\\ndeveloped amazing offline engines in alpr ocr face detection   recognition facial expression change object detection tracking counting\\nboris banushev\\n  selected experience \\n developed and backtested ai and ml quantitative trading algos using deep learning rnn dcgan vae;\\n creating optimal stock portfolio allocation using reinforcement learning;\\n retail banking merchant client expansion strategy using network science theory   ergms and networkx recommender systems and graphdb azure cosmos and native gremlin queries;\\n real time fraud detection using generative models and deep unsupervised learning som rbm\\n built endtoend ai ml cicd platform;\\n led investor negotiations and fundraising;\\n run boutique stock market broker and ultimately sold it for   0x roi;\\n participated in ipo m a and corporate valuation and due diligence;\\n  tech skills \\n deep reinforcement learning;\\n rnn lstm gru built own cell;\\n cnn transfer learning vaegan dcgan;\\n xgboost pca tsne lda sklearn;\\n unsupervised rbm som svm;\\n aws sagemaker   byomodel;\\n modifications on keras pytorch tf;\\n python pandas numpy scipy;\\n hyperparameter optimisation using reinforcement learning;\\n ai ml model training and deployment ci cd aws azure;\\n complete understanding of the whole math behind all ml;\\n graph db nosql;\\n serverless architecture  aws lambda azure functions;\\n the whole aws and azure ecosystems;\\n hadoop hive pyspark docker kubernetes;\\nnatural language processing nlp  this includes topic modelling word embeddings document embeddings sentiment analysis \\nlstm rnn gru word vec doc vec glove fasttext bert elmo attention models transformers etc\\nexcellent knowledge of c c  \\nexperience with linux and multithreading\\ngood knowledge and experience in computer visionobject  detection segmentation  and  machine  learning an advantage\\narm experience an advantage\\ngpu programming  using  cuda  or  opencl an advantage\\nsimd avx neon an advantage\\nnlp \\ndemonstrated experience in application of nlp algorithms for matching   retrieval clustering generating ontologies \\nmachine translation concept extraction entity extraction\\nexperience in big data technologies such as spark cassandra hdfs kafka druid elastic stack hive hbase etc in a complex big data product project\\n      deep learning cnns rnns reinforcement learning vaes gans\\n      machine learning regression random forests svms kmeans ensemble methods\\n      natural language processing\\n      graph databases neo j apache giraph\\n      azure bot service\\n6     azure ml studio   azure cognitive services\\n7     log analytics with nlp ml dl\\n\""
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contents_tokens = contents.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 4757)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(contents_tokens), len(contents_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contents_tokens.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_tokens = list(set(contents_tokens))\n",
    "uniq_tokens.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0x',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " 'a',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'above',\n",
       " 'abstract',\n",
       " 'achievement']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0x', '6', '6', '6', '7']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_stopwords = ['and','in','of','or','as','with','such','a','to','on','using','eg','for','the','etc','is','like','you',\n",
    "                'will','more','be','any','at','an','have','one','good','plus','experience','understanding','knowledge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_tokens = filter(lambda x: x not in my_stopwords, contents_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = list(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter = Counter(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Counter.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data', 107),\n",
       " ('learning', 87),\n",
       " ('machine', 58),\n",
       " ('python', 56),\n",
       " ('r', 39),\n",
       " ('deep', 38),\n",
       " ('hadoop', 32),\n",
       " ('models', 32),\n",
       " ('spark', 32),\n",
       " ('tools', 31),\n",
       " ('big', 29),\n",
       " ('statistical', 24),\n",
       " ('analysis', 22),\n",
       " ('skills', 22),\n",
       " ('tensorflow', 22),\n",
       " ('algorithms', 21),\n",
       " ('regression', 21),\n",
       " ('c', 20),\n",
       " ('mining', 20),\n",
       " ('ml', 20),\n",
       " ('programming', 20),\n",
       " ('hive', 19),\n",
       " ('languages', 19),\n",
       " ('processing', 19),\n",
       " ('science', 19),\n",
       " ('java', 18),\n",
       " ('scala', 18),\n",
       " ('working', 18),\n",
       " ('sql', 17),\n",
       " ('strong', 17),\n",
       " ('techniques', 16),\n",
       " ('aws', 15),\n",
       " ('databases', 14),\n",
       " ('methods', 14),\n",
       " ('engineering', 13),\n",
       " ('neural', 13),\n",
       " ('nlp', 13),\n",
       " ('text', 13),\n",
       " ('years', 13),\n",
       " ('ability', 12),\n",
       " ('azure', 12),\n",
       " ('classification', 12),\n",
       " ('language', 12),\n",
       " ('model', 12),\n",
       " ('modeling', 12),\n",
       " ('statistics', 12),\n",
       " ('analytics', 11),\n",
       " ('decision', 11),\n",
       " ('familiarity', 11),\n",
       " ('handson', 11),\n",
       " ('mapreduce', 11),\n",
       " ('matlab', 11),\n",
       " ('modelling', 11),\n",
       " ('network', 11),\n",
       " ('nosql', 11),\n",
       " ('other', 11),\n",
       " ('tableau', 11),\n",
       " ('technologies', 11),\n",
       " ('cassandra', 10),\n",
       " ('keras', 10),\n",
       " ('least', 10),\n",
       " ('numpy', 10),\n",
       " ('predictive', 10),\n",
       " ('sas', 10),\n",
       " ('software', 10),\n",
       " ('spss', 10),\n",
       " ('systems', 10),\n",
       " ('visualization', 10),\n",
       " ('building', 9),\n",
       " ('design', 9),\n",
       " ('libraries', 9),\n",
       " ('optimization', 9),\n",
       " ('pyspark', 9),\n",
       " ('reinforcement', 9),\n",
       " ('solid', 9),\n",
       " ('advanced', 8),\n",
       " ('apache', 8),\n",
       " ('cloud', 8),\n",
       " ('code', 8),\n",
       " ('computer', 8),\n",
       " ('highly', 8),\n",
       " ('large', 8),\n",
       " ('proficiency', 8),\n",
       " ('proficient', 8),\n",
       " ('theory', 8),\n",
       " ('advantage', 7),\n",
       " ('analytical', 7),\n",
       " ('based', 7),\n",
       " ('caffe', 7),\n",
       " ('cnn', 7),\n",
       " ('complex', 7),\n",
       " ('development', 7),\n",
       " ('expertise', 7),\n",
       " ('frameworks', 7),\n",
       " ('mongodb', 7),\n",
       " ('pig', 7),\n",
       " ('preferred', 7),\n",
       " ('quantitative', 7),\n",
       " ('trees', 7),\n",
       " ('ai', 6)]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigtxt = open('skills.txt').read()\n",
    "bigtxt = bigtxt.replace('.','')\n",
    "bigtxt = bigtxt.replace('’','')\n",
    "bigtxt = bigtxt.replace(',','')\n",
    "bigtxt = bigtxt.replace('–','')\n",
    "bigtxt = bigtxt.replace('-','')\n",
    "bigtxt = bigtxt.replace('(','')\n",
    "bigtxt = bigtxt.replace(')','')\n",
    "bigtxt = bigtxt.replace('/',' ')\n",
    "bigtxt = bigtxt.replace(':',' ')\n",
    "bigtxt = bigtxt.replace('&',' ')\n",
    "bigtxt = bigtxt.replace('+',' ')\n",
    "bigtxt = bigtxt.replace('1',' ')\n",
    "bigtxt = bigtxt.replace('2',' ')\n",
    "bigtxt = bigtxt.replace('3',' ')\n",
    "bigtxt = bigtxt.replace('4',' ')\n",
    "bigtxt = bigtxt.replace('5',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigtxt = bigtxt.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigtxt_tokens = bigtxt.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tokens = filter(lambda x : x not in my_stopwords, bigtxt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_valid_tokens = list(valid_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('machine', 'learning'), 52),\n",
       " (('deep', 'learning'), 22),\n",
       " (('big', 'data'), 22),\n",
       " (('data', 'mining'), 13),\n",
       " (('r', 'python'), 12),\n",
       " (('python', 'r'), 12),\n",
       " (('data', 'science'), 12),\n",
       " (('learning', 'models'), 7),\n",
       " (('neural', 'network'), 7),\n",
       " (('java', 'c'), 7),\n",
       " (('programming', 'languages'), 7),\n",
       " (('learning', 'techniques'), 7),\n",
       " (('hadoop', 'hive'), 6),\n",
       " (('sas', 'spss'), 6),\n",
       " (('text', 'mining'), 6),\n",
       " (('decision', 'trees'), 6),\n",
       " (('natural', 'language'), 6),\n",
       " (('language', 'processing'), 6),\n",
       " (('data', 'sets'), 6),\n",
       " (('reinforcement', 'learning'), 6)]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_counts = Counter(ngrams(list_valid_tokens, 2))\n",
    "ngram_counts.most_common(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
