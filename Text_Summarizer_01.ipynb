{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#!/usr/bin/env python\n# coding: utf-8\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.cluster.util import cosine_distance\nimport numpy as np\nimport networkx as nx",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def read_article(file_name):\n#     file = open(file_name, \"r\", encoding=\"utf-8\")\n    file = open(file_name, \"r\", encoding = \"ISO-8859-1\")\n    filedata = file.readlines()\n    article = filedata[0].split(\". \")\n    sentences = []\n\n    for sentence in article:\n        print(sentence)\n        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n#     sentences.pop() \n    \n    return sentences",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def sentence_similarity(sent1, sent2, stopwords=None):\n    if stopwords is None:\n        stopwords = []\n \n    sent1 = [w.lower() for w in sent1]\n    sent2 = [w.lower() for w in sent2]\n \n    all_words = list(set(sent1 + sent2))\n \n    vector1 = [0] * len(all_words)\n    vector2 = [0] * len(all_words)\n \n    # build the vector for the first sentence\n    for w in sent1:\n        if w in stopwords:\n            continue\n        vector1[all_words.index(w)] += 1\n \n    # build the vector for the second sentence\n    for w in sent2:\n        if w in stopwords:\n            continue\n        vector2[all_words.index(w)] += 1\n \n    return 1 - cosine_distance(vector1, vector2)",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def build_similarity_matrix(sentences, stop_words):\n    # Create an empty similarity matrix\n    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n \n    for idx1 in range(len(sentences)):\n        for idx2 in range(len(sentences)):\n            if idx1 == idx2: #ignore if both are same sentences\n                continue \n            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n\n    return similarity_matrix",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def generate_summary(file_name, top_n=5):\n    nltk.download(\"stopwords\")\n    stop_words = stopwords.words('english')\n    summarize_text = []\n\n    # Step 1 - Read text anc split it\n    sentences =  read_article(file_name)\n\n    # Step 2 - Generate Similary Martix across sentences\n    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n\n    # Step 3 - Rank sentences in similarity martix\n    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n    scores = nx.pagerank(sentence_similarity_graph)\n\n    # Step 4 - Sort the rank and pick top sentences\n    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n\n    for i in range(top_n):\n      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n\n    # Step 5 - Offcourse, output the summarize texr\n    print(\"Summarize Text: \\n\", \". \".join(summarize_text))",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sent1 = ['India', 'is', 'a', 'powerful', 'democracy']\nsent1 = [w.lower() for w in sent1]\nsent2 = ['USA', 'has', 'a', 'powerful', 'economy']\nsent2 = [w.lower() for w in sent2]\nsent3 = ['China', 'is', 'the', 'most', 'populous', 'nation']\nsent3 = [w.lower() for w in sent3]\nprint(sent1)\nprint(sent2)\nprint(sent3)",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['india', 'is', 'a', 'powerful', 'democracy']\n['usa', 'has', 'a', 'powerful', 'economy']\n['china', 'is', 'the', 'most', 'populous', 'nation']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentences = read_article('dummy_sample.txt')",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": "India is a large democracy and a strong economy\nUSA has a strong economy and a powerful democracy\nChina is large with a strong economy; and the most populous nation, but not a democracy.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentence_similarity(sent1, sent2, stopwords=None)",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 48,
          "data": {
            "text/plain": "0.3999999999999999"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentence_similarity(sent2, sent3, stopwords=None)",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 49,
          "data": {
            "text/plain": "0.0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentence_similarity(sent3, sent1, stopwords=None)",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "0.18257418583505536"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentence_similarity(sentences[0], sentences[1], stopwords=None), sentence_similarity(sentences[0], sentences[2], stopwords=None)",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "(0.19999999999999996, 0.18257418583505536)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(sentences), sentences[0], sentences[1], sentences[2]",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 50,
          "data": {
            "text/plain": "(3,\n ['India', 'is', 'a', 'large', 'democracy', 'and', 'a', 'strong', 'economy'],\n ['USA', 'has', 'a', 'strong', 'economy', 'and', 'a', 'powerful', 'democracy'],\n ['China',\n  'is',\n  'large',\n  'with',\n  'a',\n  'strong',\n  'economy;',\n  'and',\n  'the',\n  'most',\n  'populous',\n  'nation,',\n  'but',\n  'not',\n  'a',\n  'democracy.'])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "stop_words = stopwords.words('english')\nsimilarity_matrix = build_similarity_matrix(sentences, stop_words) \nsimilarity_matrix",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 55,
          "data": {
            "text/plain": "array([[0.        , 0.6       , 0.3380617 ],\n       [0.6       , 0.        , 0.16903085],\n       [0.3380617 , 0.16903085, 0.        ]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "stop_words = stopwords.words('english')\nsentence_similarity_matrix = build_similarity_matrix(sentences, stop_words=[]) \nsentence_similarity_matrix",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 65,
          "data": {
            "text/plain": "array([[0.        , 0.72727273, 0.56853524],\n       [0.72727273, 0.        , 0.42640143],\n       [0.56853524, 0.42640143, 0.        ]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for idx1 in range(len(sentences)):\n        for idx2 in range(len(sentences)):\n            if idx1 == idx2: #ignore if both are same sentences\n                continue \n            sentence_similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\nsentence_similarity_matrix",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 66,
          "data": {
            "text/plain": "array([[0.        , 0.6       , 0.3380617 ],\n       [0.6       , 0.        , 0.16903085],\n       [0.3380617 , 0.16903085, 0.        ]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentence_similarity_matrix",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 70,
          "data": {
            "text/plain": "array([[0.        , 0.6       , 0.3380617 ],\n       [0.6       , 0.        , 0.16903085],\n       [0.3380617 , 0.16903085, 0.        ]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_matrix)\nsentence_similarity_graph",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 71,
          "data": {
            "text/plain": "<networkx.classes.graph.Graph at 0x7f95311c67b8>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "all_words = list(set(sent1 + sent2))\nvector1 = [0] * len(all_words)\nvector2 = [0] * len(all_words)\n\nall_words, vector1, sent1\n# build the vector for the first sentence\nfor w in sent1:\n    if w in stop_words:\n        continue\n    vector1[all_words.index(w)] += 1\n\nfor w in sent2:\n    if w in stop_words:\n        continue\n    vector2[all_words.index(w)] += 1\n    \nprint(all_words)\nprint(vector1)\nprint(vector2)",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['is', 'a', 'usa', 'economy', 'has', 'democracy', 'powerful', 'india']\n[0, 0, 0, 0, 0, 1, 1, 1]\n[0, 0, 1, 1, 0, 0, 1, 0]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "vec1 = [1,1,1,1,0,0,0]\nvec2 = [1,1,0,1,0,0,0]\ndot_vec = np.dot(vec1, vec2)\n# np.mod(vec1,vec2)\nx = np.array([1,2,3,4,5])\nmag1 = np.linalg.norm(x) # Magnitude of a Vector is independent of number of Zeros in the vector\nmag1 = np.linalg.norm(vec1)\nmag2 = np.linalg.norm(vec2)\nprint(mag1)\nprint(mag2)\nprint(dot_vec)\nprint(dot_vec / (mag1 * mag2)) # Similarity Score",
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": "2.0\n1.7320508075688772\n3\n0.8660254037844387\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# vector1.dot(vector2)\n1 - cosine_distance(vec1, vec2)",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 122,
          "data": {
            "text/plain": "0.8660254037844387"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# let's begin\ngenerate_summary( \"msft.txt\", 2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "generate_summary( \"dummy_sample.txt\", 2)",
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[nltk_data] Downloading package stopwords to /home/nbuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nIndia is a large democracy and a strong economy\nUSA has a strong economy and a powerful democracy\nChina is large with a strong economy; and the most populous nation, but not a democracy.\nIndexes of top ranked_sentence order are  [(0.41479975989973483, ['India', 'is', 'a', 'large', 'democracy', 'and', 'a', 'strong', 'economy']), (0.34388831612823245, ['USA', 'has', 'a', 'strong', 'economy', 'and', 'a', 'powerful', 'democracy']), (0.24131192397203255, ['China', 'is', 'large', 'with', 'a', 'strong', 'economy;', 'and', 'the', 'most', 'populous', 'nation,', 'but', 'not', 'a', 'democracy.'])]\nSummarize Text: \n India is a large democracy and a strong economy. USA has a strong economy and a powerful democracy\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}